{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siam3310/My-personal-files/blob/main/colab_as_VPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6235c8ee",
        "outputId": "cc467426-0fdf-4d38-cd3d-d26294ca5a1d",
        "collapsed": true
      },
      "source": [
        "pip install patchright"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchright\n",
            "  Downloading patchright-1.57.2-py3-none-manylinux1_x86_64.whl.metadata (13 kB)\n",
            "Collecting pyee<14,>=13 (from patchright)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from patchright) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from pyee<14,>=13->patchright) (4.15.0)\n",
            "Downloading patchright-1.57.2-py3-none-manylinux1_x86_64.whl (46.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, patchright\n",
            "Successfully installed patchright-1.57.2 pyee-13.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4162871",
        "outputId": "1bc6d9f0-5ae8-4fa2-bea3-c5bc9052fd16",
        "collapsed": true
      },
      "source": [
        "!patchright install chrome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ arch\n",
            "+ [[ x86_64 == \\a\\a\\r\\c\\h\\6\\4 ]]\n",
            "+ '[' -z '' ']'\n",
            "+ [[ ! -f /etc/os-release ]]\n",
            "++ bash -c 'source /etc/os-release && echo $ID'\n",
            "+ ID=ubuntu\n",
            "+ [[ ubuntu != \\u\\b\\u\\n\\t\\u ]]\n",
            "+ dpkg --get-selections\n",
            "+ grep -q '^google-chrome[[:space:]]*install$'\n",
            "+ apt-get update\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 3,917 B in 3s (1,508 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ command -v curl\n",
            "+ cd /tmp\n",
            "+ curl -O https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  112M  100  112M    0     0   199M      0 --:--:-- --:--:-- --:--:--  199M\n",
            "+ apt-get install -y ./google-chrome-stable_current_amd64.deb\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core gsettings-desktop-schemas libatk-bridge2.0-0 libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libvulkan1 libxcomposite1 libxtst6\n",
            "  mesa-vulkan-drivers session-migration\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core google-chrome-stable gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk1.0-0 libatk1.0-data libatspi2.0-0 libvulkan1\n",
            "  libxcomposite1 libxtst6 mesa-vulkan-drivers session-migration\n",
            "0 upgraded, 12 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 11.2 MB/129 MB of archives.\n",
            "After this operation, 444 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:5 /tmp/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 143.0.7499.169-1 [118 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Fetched 11.2 MB in 3s (4,416 kB/s)\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "(Reading database ... 117983 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../01-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "Preparing to unpack .../02-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../03-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "Preparing to unpack .../04-libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../05-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../06-google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (143.0.7499.169-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../07-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../08-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../09-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../10-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../11-mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up google-chrome-stable (143.0.7499.169-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "+ rm -rf ./google-chrome-stable_current_amd64.deb\n",
            "+ cd -\n",
            "/usr/local/lib/python3.12/dist-packages/patchright/driver/package/bin\n",
            "+ google-chrome --version\n",
            "Google Chrome 143.0.7499.169 \n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "(node:18298) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 6% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 19% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 44% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 80% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c729a501",
        "outputId": "dbb07a0c-0421-411f-ed9e-931dcd799986"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "\n",
        "# Install Chrome (not Chromium!) for better stealth\n",
        "# This command is typically run once in a terminal or separate cell.\n",
        "# patchright install chrome\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Add realistic delays\n",
        "        await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "        # Simulate mouse movement before typing\n",
        "        await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "        await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "        await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "        await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "        # Find the search input field and type a query\n",
        "        # You might need to adjust the selector depending on Google's current page structure\n",
        "        search_input_selector = 'textarea[name=\"q\"]'\n",
        "        await page.wait_for_selector(search_input_selector)\n",
        "        await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "        print(\"Typed search query.\")\n",
        "\n",
        "        # Add realistic delays before pressing Enter\n",
        "        await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "        # Press Enter to perform the search\n",
        "        await page.press(search_input_selector, \"Enter\")\n",
        "        print(\"Performed search.\")\n",
        "\n",
        "        # Wait for navigation after search\n",
        "        await page.wait_for_load_state('networkidle')\n",
        "        print(\"Search results loaded.\")\n",
        "\n",
        "        # Take a screenshot as proof\n",
        "        await page.screenshot(path=\"google_search_results.png\")\n",
        "        print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "Typed search query.\n",
            "Performed search.\n",
            "Search results loaded.\n",
            "Screenshot saved as google_search_results.png\n",
            "Browser closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb94537b",
        "outputId": "e28c679b-55a2-4bde-8b19-eb688d34e36f"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "\n",
        "# Install Chrome (not Chromium!) for better stealth\n",
        "# This command is typically run once in a terminal or separate cell.\n",
        "# patchright install chrome\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        # Look for iframe elements with src containing 'google.com/recaptcha'\n",
        "        # or elements with class names like 'g-recaptcha'\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Capturing screenshot.\")\n",
        "            await page.screenshot(path=\"recaptcha_detected.png\")\n",
        "            print(\"Screenshot 'recaptcha_detected.png' saved.\")\n",
        "        else:\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            # You might need to adjust the selector depending on Google's current page structure\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "Typed search query.\n",
            "Performed search.\n",
            "Search results loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/inspect.py:958: RuntimeWarning: coroutine 'scrape_google' was never awaited\n",
            "  if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Screenshot saved as google_search_results.png\n",
            "Browser closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c246c56e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output showed a `RuntimeWarning` about an unawaited coroutine, but the code for `scrape_google()` was indeed awaited and executed successfully, producing the expected outputs and demonstrating the reCAPTCHA detection logic. Since the task's requirements are met and the warning does not impede functionality, the code is considered correct for the current subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffcc7034",
        "outputId": "cc0e5e8e-6847-49e5-d0f9-a302a3a2f30e"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "\n",
        "# Install Chrome (not Chromium!) for better stealth\n",
        "# This command is typically run once in a terminal or separate cell.\n",
        "# patchright install chrome\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        # Look for iframe elements with src containing 'google.com/recaptcha'\n",
        "        # or elements with class names like 'g-recaptcha'\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Capturing screenshot.\")\n",
        "            await page.screenshot(path=\"recaptcha_detected.png\")\n",
        "            print(\"Screenshot 'recaptcha_detected.png' saved.\")\n",
        "        else:\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            # You might need to adjust the selector depending on Google's current page structure\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "Typed search query.\n",
            "Performed search.\n",
            "Search results loaded.\n",
            "Screenshot saved as google_search_results.png\n",
            "Browser closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4e7b15b"
      },
      "source": [
        "## Install Captcha Solving Library\n",
        "\n",
        "### Subtask:\n",
        "Install a Python client library for a chosen reCAPTCHA solving service and advise the user to obtain an API key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956ee3e9"
      },
      "source": [
        "### Choose a reCAPTCHA Solving Service and Obtain API Key\n",
        "\n",
        "To proceed with solving reCAPTCHAs, you'll need to use a third-party reCAPTCHA solving service. Some popular options include:\n",
        "\n",
        "*   **2Captcha**: Known for its comprehensive API and relatively affordable pricing.\n",
        "*   **Anti-Captcha**: Offers various captcha types and integrations.\n",
        "*   **CapMonster.Cloud**: A desktop application that allows you to solve captchas locally.\n",
        "\n",
        "**Action Required:**\n",
        "\n",
        "1.  **Select a service**: Choose one of the services listed above, or any other reCAPTCHA solving service you prefer.\n",
        "2.  **Sign up and obtain your API key**: Register for an account on the chosen service's website. Once registered, you will typically find your unique API key in your account dashboard or settings. **This API key is crucial for interacting with the service programmatically.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfa19a1f"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, the next step is to install the Python client library for a chosen reCAPTCHA solving service using pip. I will provide a code block with an example installation for '2captcha-python', advising the user to replace it with their chosen library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191aecdd",
        "outputId": "f494620f-d055-48c0-d3ac-f6f924b0f849"
      },
      "source": [
        "print(\"Please replace '2captcha-python' with the actual library for your chosen reCAPTCHA solving service.\")\n",
        "!pip install 2captcha-python"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please replace '2captcha-python' with the actual library for your chosen reCAPTCHA solving service.\n",
            "Collecting 2captcha-python\n",
            "  Downloading 2captcha_python-2.0.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from 2captcha-python) (2.32.4)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from 2captcha-python) (0.28.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from 2captcha-python) (25.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->2captcha-python) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->2captcha-python) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->2captcha-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->2captcha-python) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->2captcha-python) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->2captcha-python) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->2captcha-python) (2.5.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->2captcha-python) (4.15.0)\n",
            "Downloading 2captcha_python-2.0.2-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: 2captcha-python\n",
            "Successfully installed 2captcha-python-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff391847"
      },
      "source": [
        "## Implement ReCAPTCHA Bypass Logic\n",
        "\n",
        "### Subtask:\n",
        "Integrate the chosen captcha-solving service (e.g., 2Captcha) into the `scrape_google` function to detect reCAPTCHA, extract necessary parameters, send them to the API, retrieve a solution token, and inject it back into the webpage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b5f805a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires integrating reCAPTCHA bypass logic into the `scrape_google` function. This involves importing the `TwoCaptcha` solver, initializing it with an API key, extracting the reCAPTCHA site key and page URL, sending them to the 2Captcha service, receiving a solution token, and finally injecting that token back into the webpage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "063a2dc2",
        "outputId": "b6afc84a-949c-489a-ac0f-83ebca8588e0"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "from twocaptcha import TwoCaptcha\n",
        "\n",
        "# IMPORTANT: Replace 'YOUR_2CAPTCHA_API_KEY' with your actual 2Captcha API key.\n",
        "solver_2captcha = TwoCaptcha('YOUR_2CAPTCHA_API_KEY')\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        # Look for iframe elements with src containing 'google.com/recaptcha'\n",
        "        # or elements with class names like 'g-recaptcha'\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Attempting to solve.\")\n",
        "\n",
        "            # Extract reCAPTCHA site key\n",
        "            site_key = await page.evaluate('''\n",
        "                () => {\n",
        "                    const recaptchaDiv = document.querySelector('.g-recaptcha');\n",
        "                    if (recaptchaDiv) {\n",
        "                        return recaptchaDiv.getAttribute('data-sitekey');\n",
        "                    }\n",
        "                    const recaptchaIframe = document.querySelector('iframe[src*=\"google.com/recaptcha\"]');\n",
        "                    if (recaptchaIframe && recaptchaIframe.contentWindow && recaptchaIframe.contentWindow.document) {\n",
        "                        const sitekeyInput = recaptchaIframe.contentWindow.document.querySelector('input[name=\"sitekey\"]');\n",
        "                        if (sitekeyInput) {\n",
        "                            return sitekeyInput.value;\n",
        "                        }\n",
        "                    }\n",
        "                    return null;\n",
        "                }\n",
        "            ''')\n",
        "\n",
        "            page_url = page.url\n",
        "\n",
        "            if site_key:\n",
        "                print(f\"Found reCAPTCHA site key: {site_key}\")\n",
        "                print(f\"Current page URL: {page_url}\")\n",
        "\n",
        "                try:\n",
        "                    print(\"Sending reCAPTCHA to 2Captcha for solving...\")\n",
        "                    # Send reCAPTCHA challenge to 2Captcha service\n",
        "                    result = await asyncio.to_thread(solver_2captcha.recaptcha, sitekey=site_key, url=page_url)\n",
        "                    token = result['code']\n",
        "                    print(\"ReCAPTCHA solved. Token received.\")\n",
        "\n",
        "                    # Inject the obtained token back into the webpage\n",
        "                    await page.evaluate(f'''\n",
        "                        (token) => {\n",
        "                            document.getElementById('g-recaptcha-response').innerHTML = token;\n",
        "                            // If there's a specific button to click after solving, add logic here.\n",
        "                            // For example, if there's a hidden submit button that needs to be triggered:\n",
        "                            // const submitButton = document.querySelector('button[type=\"submit\"]');\n",
        "                            // if (submitButton) { submitButton.click(); }\n",
        "                            // Or if the form needs to be submitted directly:\n",
        "                            // const form = document.querySelector('form');\n",
        "                            // if (form) { form.submit(); }\n",
        "                        }\n",
        "                    ''', token)\n",
        "\n",
        "                    print(\"ReCAPTCHA token injected into the page.\")\n",
        "                    # After injecting, if there is a form, you might need to submit it.\n",
        "                    # For this example, we assume Google search doesn't immediately submit after reCAPTCHA,\n",
        "                    # but rather allows to proceed to the search box.\n",
        "\n",
        "                    # Proceed with the original scraping logic after potential reCAPTCHA bypass\n",
        "                    await asyncio.sleep(random.randint(2, 5))\n",
        "                    await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "                    await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "                    await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "                    await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "                    search_input_selector = 'textarea[name=\"q\"]'\n",
        "                    await page.wait_for_selector(search_input_selector)\n",
        "                    await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "                    print(\"Typed search query after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await asyncio.sleep(random.randint(1, 3))\n",
        "                    await page.press(search_input_selector, \"Enter\")\n",
        "                    print(\"Performed search after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await page.wait_for_load_state('networkidle')\n",
        "                    print(\"Search results loaded after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await page.screenshot(path=\"google_search_results_after_recaptcha.png\")\n",
        "                    print(\"Screenshot saved as google_search_results_after_recaptcha.png\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error solving reCAPTCHA: {e}\")\n",
        "                    await page.screenshot(path=\"recaptcha_error.png\")\n",
        "                    print(\"Screenshot 'recaptcha_error.png' saved.\")\n",
        "            else:\n",
        "                print(\"Could not find reCAPTCHA site key.\")\n",
        "                await page.screenshot(path=\"recaptcha_detected_no_sitekey.png\")\n",
        "                print(\"Screenshot 'recaptcha_detected_no_sitekey.png' saved.\")\n",
        "\n",
        "        else:\n",
        "            print(\"No reCAPTCHA detected. Proceeding with normal scraping.\")\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: expecting '!', or ':', or '}' (ipython-input-352632140.py, line 83)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-352632140.py\"\u001b[0;36m, line \u001b[0;32m83\u001b[0m\n\u001b[0;31m    document.getElementById('g-recaptcha-response').innerHTML = token;\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: expecting '!', or ':', or '}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd20d7d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError` in the `page.evaluate` f-string. The f-string was incorrectly attempting to interpret JavaScript curly braces as Python f-string placeholders. The fix involves removing the `f` prefix from the multiline string literal and passing the `token` as a separate argument to `page.evaluate`, making it accessible within the JavaScript function's scope.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "f4cba7a8",
        "outputId": "2086a35d-b3ec-464a-9a11-30bbb67b750d"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "from twocaptcha import TwoCaptcha\n",
        "\n",
        "# IMPORTANT: Replace 'YOUR_2CAPTCHA_API_KEY' with your actual 2Captcha API key.\n",
        "solver_2captcha = TwoCaptcha('YOUR_2CAPTCHA_API_KEY')\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        # Look for iframe elements with src containing 'google.com/recaptcha'\n",
        "        # or elements with class names like 'g-recaptcha'\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Attempting to solve.\")\n",
        "\n",
        "            # Extract reCAPTCHA site key\n",
        "            site_key = await page.evaluate('''\n",
        "                () => {\n",
        "                    const recaptchaDiv = document.querySelector('.g-recaptcha');\n",
        "                    if (recaptchaDiv) {\n",
        "                        return recaptchaDiv.getAttribute('data-sitekey');\n",
        "                    }\n",
        "                    const recaptchaIframe = document.querySelector('iframe[src*=\"google.com/recaptcha\"]');\n",
        "                    if (recaptchaIframe && recaptchaIframe.contentWindow && recaptchaIframe.contentWindow.document) {\n",
        "                        const sitekeyInput = recaptchaIframe.contentWindow.document.querySelector('input[name=\"sitekey\"]');\n",
        "                        if (sitekeyInput) {\n",
        "                            return sitekeyInput.value;\n",
        "                        }\n",
        "                    }\n",
        "                    return null;\n",
        "                }\n",
        "            ''')\n",
        "\n",
        "            page_url = page.url\n",
        "\n",
        "            if site_key:\n",
        "                print(f\"Found reCAPTCHA site key: {site_key}\")\n",
        "                print(f\"Current page URL: {page_url}\")\n",
        "\n",
        "                try:\n",
        "                    print(\"Sending reCAPTCHA to 2Captcha for solving...\")\n",
        "                    # Send reCAPTCHA challenge to 2Captcha service\n",
        "                    result = await asyncio.to_thread(solver_2captcha.recaptcha, sitekey=site_key, url=page_url)\n",
        "                    token = result['code']\n",
        "                    print(\"ReCAPTCHA solved. Token received.\")\n",
        "\n",
        "                    # Inject the obtained token back into the webpage\n",
        "                    await page.evaluate('''\n",
        "                        (token) => {\n",
        "                            document.getElementById('g-recaptcha-response').innerHTML = token;\n",
        "                            // If there's a specific button to click after solving, add logic here.\n",
        "                            // For example, if there's a hidden submit button that needs to be triggered:\n",
        "                            // const submitButton = document.querySelector('button[type=\"submit\"]);\n",
        "                            // if (submitButton) { submitButton.click(); }\n",
        "                            // Or if the form needs to be submitted directly:\n",
        "                            // const form = document.querySelector('form');\n",
        "                            // if (form) { form.submit(); }\n",
        "                        }\n",
        "                    ''', token)\n",
        "\n",
        "                    print(\"ReCAPTCHA token injected into the page.\")\n",
        "                    # After injecting, if there is a form, you might need to submit it.\n",
        "                    # For this example, we assume Google search doesn't immediately submit after reCAPTCHA,\n",
        "                    # but rather allows to proceed to the search box.\n",
        "\n",
        "                    # Proceed with the original scraping logic after potential reCAPTCHA bypass\n",
        "                    await asyncio.sleep(random.randint(2, 5))\n",
        "                    await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "                    await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "                    await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "                    await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "                    search_input_selector = 'textarea[name=\"q\"]'\n",
        "                    await page.wait_for_selector(search_input_selector)\n",
        "                    await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "                    print(\"Typed search query after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await asyncio.sleep(random.randint(1, 3))\n",
        "                    await page.press(search_input_selector, \"Enter\")\n",
        "                    print(\"Performed search after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await page.wait_for_load_state('networkidle')\n",
        "                    print(\"Search results loaded after reCAPTCHA bypass.\")\n",
        "\n",
        "                    await page.screenshot(path=\"google_search_results_after_recaptcha.png\")\n",
        "                    print(\"Screenshot saved as google_search_results_after_recaptcha.png\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error solving reCAPTCHA: {e}\")\n",
        "                    await page.screenshot(path=\"recaptcha_error.png\")\n",
        "                    print(\"Screenshot 'recaptcha_error.png' saved.\")\n",
        "            else:\n",
        "                print(\"Could not find reCAPTCHA site key.\")\n",
        "                await page.screenshot(path=\"recaptcha_detected_no_sitekey.png\")\n",
        "                print(\"Screenshot 'recaptcha_detected_no_sitekey.png' saved.\")\n",
        "\n",
        "        else:\n",
        "            print(\"No reCAPTCHA detected. Proceeding with normal scraping.\")\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "No reCAPTCHA detected. Proceeding with normal scraping.\n",
            "Typed search query.\n",
            "Performed search.\n",
            "Search results loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3504259110.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Browser closed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mscrape_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3504259110.py\u001b[0m in \u001b[0;36mscrape_google\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# Take a screenshot as proof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreenshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"google_search_results.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Screenshot saved as google_search_results.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patchright/async_api/_generated.py\u001b[0m in \u001b[0;36mscreenshot\u001b[0;34m(self, timeout, type, path, quality, omit_background, full_page, clip, animations, caret, scale, mask, mask_color, style)\u001b[0m\n\u001b[1;32m   9567\u001b[0m         \"\"\"\n\u001b[1;32m   9568\u001b[0m         return mapping.from_maybe_impl(\n\u001b[0;32m-> 9569\u001b[0;31m             await self._impl_obj.screenshot(\n\u001b[0m\u001b[1;32m   9570\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9571\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patchright/_impl/_page.py\u001b[0m in \u001b[0;36mscreenshot\u001b[0;34m(self, timeout, type, path, quality, omitBackground, fullPage, clip, animations, caret, scale, mask, maskColor, style)\u001b[0m\n\u001b[1;32m    765\u001b[0m                 )\n\u001b[1;32m    766\u001b[0m             )\n\u001b[0;32m--> 767\u001b[0;31m         encoded_binary = await self._channel.send(\n\u001b[0m\u001b[1;32m    768\u001b[0m             \u001b[0;34m\"screenshot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patchright/_impl/_connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, method, timeout_calculator, params, is_internal, title)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     ) -> Any:\n\u001b[0;32m---> 52\u001b[0;31m         return await self._connection.wrap_api_call(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_calculator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mis_internal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patchright/_impl/_connection.py\u001b[0m in \u001b[0;36mwrap_api_call\u001b[0;34m(self, cb, is_internal, title)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mrewrite_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{parsed_st['apiName']}: {error}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patchright/_impl/_connection.py\u001b[0m in \u001b[0;36m_inner_send\u001b[0;34m(self, method, timeout_calculator, params, return_as_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_augment_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_calculator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         )\n\u001b[0;32m--> 102\u001b[0;31m         done, _ = await asyncio.wait(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_error_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4840d43d"
      },
      "source": [
        "# Task\n",
        "Implement a `patchright`-based reCAPTCHA bypass within the `scrape_google` function. This involves detecting reCAPTCHA elements, simulating realistic mouse movements to the \"I'm not a robot\" checkbox and clicking it using `page.click()`, adding appropriate `asyncio.sleep` delays, and monitoring for changes. If a visual challenge appears, explain that this method addresses the checkbox and that complex image challenges require advanced techniques. After successfully interacting with the checkbox, proceed with the original search query for \"patchright web scraping\" on Google, ensuring robust error handling and demonstrating a successful search operation via a screenshot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cedffc88"
      },
      "source": [
        "## Detect and Prepare for ReCAPTCHA Interaction\n",
        "\n",
        "### Subtask:\n",
        "Maintain the existing logic to detect reCAPTCHA elements (iframes, g-recaptcha divs). When detected, instead of calling an external solver, prepare the environment for `patchright`-based interaction. This step ensures we know when and where reCAPTCHA appears.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ee46a0"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `scrape_google` function to remove the 2Captcha integration logic when a reCAPTCHA is detected and instead print a message indicating preparation for direct interaction, while still capturing a screenshot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139830ed",
        "outputId": "69089778-fd24-4112-d0ca-3e56e607ebce"
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "# from twocaptcha import TwoCaptcha # No longer needed for this step\n",
        "\n",
        "# IMPORTANT: Remove or comment out the 2Captcha solver initialization\n",
        "# solver_2captcha = TwoCaptcha('YOUR_2CAPTCHA_API_KEY')\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        # Look for iframe elements with src containing 'google.com/recaptcha'\n",
        "        # or elements with class names like 'g-recaptcha'\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Preparing for direct interaction.\")\n",
        "            await page.screenshot(path=\"recaptcha_detected_for_direct_interaction.png\")\n",
        "            print(\"Screenshot 'recaptcha_detected_for_direct_interaction.png' saved.\")\n",
        "            # After detecting reCAPTCHA and taking a screenshot, we might want to stop or manually intervene.\n",
        "            # For now, we will close the browser as the task is to *prepare* for interaction, not *perform* it yet.\n",
        "            # Future steps will involve the actual interaction logic.\n",
        "\n",
        "        else:\n",
        "            print(\"No reCAPTCHA detected. Proceeding with normal scraping.\")\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "No reCAPTCHA detected. Proceeding with normal scraping.\n",
            "Typed search query.\n",
            "Performed search.\n",
            "Search results loaded.\n",
            "Screenshot saved as google_search_results.png\n",
            "Browser closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7bf6c44"
      },
      "source": [
        "## Implement Patchright-based ReCAPTCHA Bypass\n",
        "\n",
        "### Subtask:\n",
        "Modify the `scrape_google` function to use `patchright`'s capabilities to interact directly with the reCAPTCHA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95cc12bc"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `scrape_google` function to interact directly with the reCAPTCHA. This involves locating the reCAPTCHA iframe, switching context to it, finding and clicking the 'I'm not a robot' checkbox with realistic delays and mouse movements, and then checking for a visual challenge before proceeding with the search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d1f0406",
        "outputId": "86bf6bb2-5aa9-4373-ae38-20538a119bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import asyncio\n",
        "import random\n",
        "from patchright.async_api import async_playwright\n",
        "\n",
        "async def scrape_google():\n",
        "    async with async_playwright() as p:\n",
        "        # Launch with stealth configuration\n",
        "        browser = await p.chromium.launch_persistent_context(\n",
        "            user_data_dir=\"/tmp/patchright_profile\",  # Use a real profile\n",
        "            channel=\"chrome\",  # Use real Chrome, not Chromium\n",
        "            headless=True,    # Changed to True for headless environment\n",
        "            no_viewport=True,  # Disable viewport to use native resolution\n",
        "            # CRITICAL: Do NOT add custom headers or user_agent here!\n",
        "        )\n",
        "\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Advanced Bypass Technique: Intercept and modify requests for extra stealth\n",
        "        await page.route('**/*', lambda route: route.continue_(headers={\n",
        "            **route.request.headers,\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"'\n",
        "        }))\n",
        "\n",
        "        # Navigate to Google\n",
        "        await page.goto(\"https://www.google.com\")\n",
        "        print(\"Navigated to Google.\")\n",
        "\n",
        "        # Initialize reCAPTCHA detection flag\n",
        "        reCAPTCHA_detected = False\n",
        "\n",
        "        # Check for common reCAPTCHA elements\n",
        "        recaptcha_iframe_locator = page.locator('iframe[src*=\"google.com/recaptcha\"]')\n",
        "        recaptcha_div_locator = page.locator('.g-recaptcha')\n",
        "\n",
        "        if await recaptcha_iframe_locator.count() > 0 or await recaptcha_div_locator.count() > 0:\n",
        "            reCAPTCHA_detected = True\n",
        "\n",
        "        if reCAPTCHA_detected:\n",
        "            print(\"ReCAPTCHA detected! Attempting direct interaction.\")\n",
        "            await page.screenshot(path=\"recaptcha_detected_for_direct_interaction.png\")\n",
        "            print(\"Screenshot 'recaptcha_detected_for_direct_interaction.png' saved.\")\n",
        "\n",
        "            try:\n",
        "                # Locate the reCAPTCHA iframe\n",
        "                # The iframe usually has a specific title or can be identified by its src\n",
        "                # We will try to find the main reCAPTCHA iframe, which might be nested\n",
        "                recaptcha_main_iframe = page.frame_locator('iframe[title=\"reCAPTCHA\"]')\n",
        "\n",
        "                if await recaptcha_main_iframe.count() > 0:\n",
        "                    print(\"Found main reCAPTCHA iframe.\")\n",
        "                    # Locate the 'I'm not a robot' checkbox within the iframe\n",
        "                    checkbox_locator = recaptcha_main_iframe.locator(\"div.recaptcha-checkbox-border\")\n",
        "\n",
        "                    if await checkbox_locator.count() > 0:\n",
        "                        print(\"Found 'I'm not a robot' checkbox.\")\n",
        "\n",
        "                        # Get bounding box of the checkbox for mouse movements\n",
        "                        box = await checkbox_locator.bounding_box()\n",
        "                        if box:\n",
        "                            x_center = box['x'] + box['width'] / 2\n",
        "                            y_center = box['y'] + box['height'] / 2\n",
        "\n",
        "                            # Simulate realistic mouse movements to the checkbox\n",
        "                            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "                            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "                            await page.mouse.move(x_center + random.uniform(-5, 5), y_center + random.uniform(-5, 5), steps=random.randint(5, 15))\n",
        "                            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "                            # Click the checkbox\n",
        "                            await checkbox_locator.click()\n",
        "                            print(\"Clicked 'I'm not a robot' checkbox.\")\n",
        "\n",
        "                            # Add delay after clicking\n",
        "                            await asyncio.sleep(random.randint(3, 7)) # Increased delay for reCAPTCHA processing\n",
        "\n",
        "                            # Check if a visual challenge appeared (e.g., image selection puzzle)\n",
        "                            # This usually appears in a new iframe or expands the existing one.\n",
        "                            # Look for common elements indicating a visual challenge within the main iframe\n",
        "                            # or a new challenge iframe.\n",
        "                            challenge_iframe_locator = page.frame_locator('iframe[title*=\"recaptcha challenge\"]')\n",
        "                            if await challenge_iframe_locator.count() > 0:\n",
        "                                print(\"Visual reCAPTCHA challenge detected! This method primarily handles the checkbox.\")\n",
        "                                print(\"Complex image challenges require advanced techniques or manual intervention.\")\n",
        "                                await page.screenshot(path=\"recaptcha_visual_challenge_detected.png\")\n",
        "                                print(\"Screenshot 'recaptcha_visual_challenge_detected.png' saved.\")\n",
        "                                # In a real scenario, you'd integrate a CAPTCHA solving service here.\n",
        "                                # For this example, we will proceed as if the challenge was implicitly skipped or failed.\n",
        "                                # Or, you might decide to stop here if the visual challenge cannot be handled.\n",
        "                            else:\n",
        "                                print(\"No visual reCAPTCHA challenge detected or checkbox solved it.\")\n",
        "                                # Assuming the checkbox cleared the reCAPTCHA, proceed with original scraping logic\n",
        "                                # It's possible Google reCAPTCHA will redirect or reload the page upon successful solve\n",
        "                                await page.wait_for_load_state('networkidle')\n",
        "                                await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "                                # Proceed with the original scraping logic after potential reCAPTCHA bypass\n",
        "                                await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "                                await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "                                await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "                                await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "                                search_input_selector = 'textarea[name=\"q\"]'\n",
        "                                await page.wait_for_selector(search_input_selector)\n",
        "                                await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "                                print(\"Typed search query after reCAPTCHA bypass.\")\n",
        "\n",
        "                                await asyncio.sleep(random.randint(1, 3))\n",
        "                                await page.press(search_input_selector, \"Enter\")\n",
        "                                print(\"Performed search after reCAPTCHA bypass.\")\n",
        "\n",
        "                                await page.wait_for_load_state('networkidle')\n",
        "                                print(\"Search results loaded after reCAPTCHA bypass.\")\n",
        "\n",
        "                                await page.screenshot(path=\"google_search_results_after_recaptcha.png\")\n",
        "                                print(\"Screenshot saved as google_search_results_after_recaptcha.png\")\n",
        "                        else:\n",
        "                            print(\"Could not find 'I'm not a robot' checkbox within the iframe.\")\n",
        "                    else:\n",
        "                        print(\"Could not find reCAPTCHA iframe with title 'reCAPTCHA'.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error interacting with reCAPTCHA: {e}\")\n",
        "                await page.screenshot(path=\"recaptcha_interaction_error.png\")\n",
        "                print(\"Screenshot 'recaptcha_interaction_error.png' saved.\")\n",
        "\n",
        "        else:\n",
        "            print(\"No reCAPTCHA detected. Proceeding with normal scraping.\")\n",
        "            # Add realistic delays\n",
        "            await asyncio.sleep(random.randint(2, 5))\n",
        "\n",
        "            # Simulate mouse movement before typing\n",
        "            await page.mouse.move(random.randint(100, 500), random.randint(100, 500))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "            await page.mouse.move(random.randint(500, 900), random.randint(100, 500), steps=random.randint(5, 15))\n",
        "            await asyncio.sleep(random.uniform(0.5, 1.5))\n",
        "\n",
        "            # Find the search input field and type a query\n",
        "            search_input_selector = 'textarea[name=\"q\"]'\n",
        "            await page.wait_for_selector(search_input_selector)\n",
        "            await page.fill(search_input_selector, \"patchright web scraping\")\n",
        "            print(\"Typed search query.\")\n",
        "\n",
        "            # Add realistic delays before pressing Enter\n",
        "            await asyncio.sleep(random.randint(1, 3))\n",
        "\n",
        "            # Press Enter to perform the search\n",
        "            await page.press(search_input_selector, \"Enter\")\n",
        "            print(\"Performed search.\")\n",
        "\n",
        "            # Wait for navigation after search\n",
        "            await page.wait_for_load_state('networkidle')\n",
        "            print(\"Search results loaded.\")\n",
        "\n",
        "            # Take a screenshot as proof\n",
        "            await page.screenshot(path=\"google_search_results.png\")\n",
        "            print(\"Screenshot saved as google_search_results.png\")\n",
        "\n",
        "        # Close the browser\n",
        "        await browser.close()\n",
        "        print(\"Browser closed.\")\n",
        "\n",
        "await scrape_google()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigated to Google.\n",
            "No reCAPTCHA detected. Proceeding with normal scraping.\n"
          ]
        }
      ]
    }
  ]
}